= Nodehwtest Testset, aka Node Level Hardware Testing =

Cbench has a growing low-level hardware testing capability.  The capability includes opensource testing packages (such as 'memtester', Cerberus Test Control system', STREAMS, etc.), Cbench scripts, and the Cbench `hw_test` framework. The goal is to facilitate scalable node-level hardware testing. Much of the rest of Cbench is aimed at testing/benchmarking/characterizing an integrated HPC system at the MPI level. For more information on the `hw_test` framework see README.hw_test.

This capability is captured in a test set named `nodehwtest`. A normal Cbench `make`, `make install`, `make installtests` sequence will compile and install all the typically supported tests and scripts that are part of `nodehwtest`.  There are some tests that are supported within `nodehwtest` that aren't always available due to licensing restrictions (`nodeperf` for example) or their dependence on certain hardware components such as a type of high-speed  interconnect (Myrinet, Infiniband, etc.).

The key utilities in `nodehwtest` are `node_hw_test` and `nodehwtest_output_parse.pl`.

`node_hw_test` is the utility responsible for running all tests supported by the Cbench hw_test modules. `node_hw_test` can be simply run by hand on a node or on many nodes via some sort of remote execution method like rsh, pdsh, ssh, etc. The key point is that `node_hw_test` must run on every node that you want to test.

`nodehwtest_output_parse.pl` is responsible, just like all the other Cbench output parsers, for parsing the output in the nodehwtest test set. Currently this means output generated by the node_hw_test utility but may expand in the future. `nodehwtest_output_parse.pl` has many options that control how much test data is parsed and analyzed. `nodehwtest_output_parse.pl` uses a statistical approach to characterize parsed node test result data. The idea is to run tests on a set of nodes that are very similar, and then characterize that test data statistically based on mean, max, min, and standard deviation. Characterized data is then captured into a set of target hardware values.  These target hardware values can then be used as the basis for flagging nodes that fall outside the characteristic pattern as "bad".  The goal is to filter out all the nodes that are performing within norms and only call attention to the nodes that are not. This facilitates being able to test a lot of nodes in a scalable manner.

The actual heuristic that `nodehwtest_output_parse.pl` uses is based on basic standard deviation principles. Given a set of normally distributed samples,  the mean value of those samples, and the standard deviation of those samples it is true that:
	 1. 95% of those samples will be within +/- 2*stddeviation of the mean
	 2. 68% of those samples will be within +/- 1*stddeviation of the mean
We use this in `nodehwtest_output_parse.pl` to flag bad nodes. Nodes with test values that differ from the test value mean by greater than two standard deviations are flagged with a 95% probability of actually being bad in some hardware respect.  Nodes with test values differing from the test value mean by more than one standard deviation but less than two have a 68% probability of having hardware issues.

Nodehwtest utilities use the Cbench test identifier approach for organizing test data. Organizing test data is of particular importance in this test set because statistical data is dealt with by `nodehwtest_output_parse.pl` at the test identifier level.  In other words, the statistical profile built by `nodehwtest_output_parse.pl` for a test identifier is valid only for the data within that test identifier and for the nodes from which the test data was gathered.  The better your test data is organized the less statistical false negatives will be generated by `nodehwtest_output_parse.pl`.  

The `nodehwtest` test set uses the idea of test runs and test iterations. A test run encapsulates all the tests and test output that is run during a  single invocation of `node_hw_test`. A single test run may consist of 1 or more test iterations (see the `--iter` parameter to `node_hw_test`). The more test runs and test iterations that are used to build the characteristic profile for a test identifier, the better the stats will be as well.

Ok....so what does all this mean in practice?

Organize your `node_hw_test` run data using the `--ident` parameter intelligently.  Some examples:

 1. For all racks in a system contain homogeneous nodes, use a test identifier per rack in the system
 2. For all compute nodes in a system are homogeneous, use a test identifier for all compute nodes
 3. For all compute nodes are homogeneous except that some have more memory, use a test identifier for the two sets of nodes based on the amount of memory

Here is an example usage sequence:
	1. Run `node_hw_test` on a set of homogeneous nodes using multiple test iterations. For example:
           {{{
pdsh -w n[0-127] "node_hw_test --ident compute --iterations 20"
           }}}
	2. Characterize the test data and save the target hardware values:
	   {{{
nodehwtest_output_parse.pl --ident compute --characterize --savetarget
           }}}

	   This command will analyze the data, characterize it, save a target values file named `$BENCH_TEST/nodehwtest/compute/target_hw_values`, and also flag test values on any of the nodes that fall outside the statistical norms for compute nodes n0 through n127.
	3. Fix a node that was having issues, n10, and rerun `node_hw_test` on it.
	4. Run `nodehwtest_output_parse.pl` to parse the new test data for n10 and compare it to the target hardware values for the group:
{{{
nodehwtest_output_parse.pl --ident compute --match n10
}}}
Both `node_hw_test` and `nodehwtest_output_parse.pl` have parameters to only run and parse tests from certain test classes (i.e. memory, cpu, disk) or only  specific tests.

To see what specific tests Cbench supports in the `hw_test` framework look at the modules in `$CBENCHOME/perllib/hw_test`.




